{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:13:41.314876Z",
     "start_time": "2025-09-25T20:13:39.425976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USE {\n",
    "    repositories {\n",
    "        mavenLocal()\n",
    "    }\n",
    "    dependencies {\n",
    "        implementation(\"sk.ainet:kotlin-notebook:0.0.1\")\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-25T20:25:07.067579Z",
     "start_time": "2025-09-25T20:25:06.811499Z"
    }
   },
   "source": [
    "import sk.ainet.core.tensor.FP32\n",
    "import sk.ainet.core.tensor.backend.CpuBackend\n",
    "import sk.ainet.core.tensor.Shape\n",
    "import sk.ainet.core.tensor.backend.CpuTensorFP32\n",
    "import sk.ainet.nn.dsl.network\n",
    "import sk.ainet.nn.Module\n",
    "import kotlin.math.*\n",
    "\n",
    "// Define explicit weights and biases for reproducible results\n",
    "val sinNetwork: Module<FP32, kotlin.Float> = network<FP32, Float> {\n",
    "    input(1)  // Single input for x value\n",
    "\n",
    "    // First hidden layer: 1 -> 16 neurons\n",
    "    dense(16) {\n",
    "        // Weights: 16x1 matrix - explicitly defined values\n",
    "        weights { shape ->\n",
    "            CpuTensorFP32.fromArray(\n",
    "                shape,\n",
    "                floatArrayOf(\n",
    "                    0.5f, -0.3f, 0.8f, -0.2f, 0.6f, -0.4f, 0.7f, -0.1f,\n",
    "                    0.9f, -0.5f, 0.3f, -0.7f, 0.4f, -0.6f, 0.2f, -0.8f\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "\n",
    "        // Bias: 16 values - explicitly defined\n",
    "        bias { shape ->\n",
    "            CpuTensorFP32.fromArray(\n",
    "                shape,\n",
    "                floatArrayOf(\n",
    "                    0.1f, -0.1f, 0.2f, -0.2f, 0.0f, 0.3f, -0.3f, 0.1f,\n",
    "                    -0.1f, 0.2f, -0.2f, 0.0f, 0.3f, -0.3f, 0.1f, -0.1f\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "\n",
    "        activation = { tensor ->\n",
    "            with(tensor) { relu() }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Second hidden layer: 16 -> 16 neurons\n",
    "    dense(16) {\n",
    "        // Weights: 16x16 matrix - explicitly defined values\n",
    "        weights { shape ->\n",
    "            CpuTensorFP32.fromArray(\n",
    "                shape,\n",
    "                floatArrayOf(\n",
    "                    0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f,\n",
    "                    -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f,\n",
    "                    0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f,\n",
    "                    -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f,\n",
    "                    0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f,\n",
    "                    -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f,\n",
    "                    0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f,\n",
    "                    -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f,\n",
    "                    0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f,\n",
    "                    -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f,\n",
    "                    0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f,\n",
    "                    -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f, 0.2f,\n",
    "                    0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f, -0.1f,\n",
    "                    -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f, 0.2f,\n",
    "                    0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f, -0.1f,\n",
    "                    -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.2f, -0.1f, 0.5f\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "\n",
    "        // Bias: 16 values - explicitly defined\n",
    "        bias { shape ->\n",
    "            CpuTensorFP32.fromArray(\n",
    "                shape,\n",
    "                floatArrayOf(\n",
    "                    0.05f, -0.05f, 0.1f, -0.1f, 0.0f, 0.15f, -0.15f, 0.05f,\n",
    "                    -0.05f, 0.1f, -0.1f, 0.0f, 0.15f, -0.15f, 0.05f, -0.05f\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "        activation = { tensor ->\n",
    "            with(tensor) { relu() }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Output layer: 16 -> 1 neuron\n",
    "    dense(1) {\n",
    "        // Weights: 1x16 matrix - explicitly defined values\n",
    "        weights { shape ->\n",
    "            CpuTensorFP32.fromArray(\n",
    "                shape,\n",
    "                floatArrayOf(\n",
    "                    0.3f, -0.2f, 0.4f, -0.1f, 0.5f, -0.3f, 0.2f, -0.4f,\n",
    "                    0.1f, -0.5f, 0.3f, -0.2f, 0.4f, -0.1f, 0.5f, -0.3f\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "\n",
    "        // Bias: single value - explicitly defined\n",
    "        bias { shape ->\n",
    "            CpuTensorFP32.fromArray(shape, floatArrayOf(0.0f))\n",
    "        }\n",
    "\n",
    "        // No activation for output layer (linear output)\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:25:07.617912Z",
     "start_time": "2025-09-25T20:25:07.584903Z"
    }
   },
   "cell_type": "code",
   "source": "sinNetwork",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sk.ainet.nn.topology.MLP@3ed549dc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:25:08.489199Z",
     "start_time": "2025-09-25T20:25:08.187077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val numSamples = 100\n",
    "val maxInput = PI.toFloat() / 2f  // π/2\n",
    "\n",
    "println(\"Neural Network vs Math.sin() Comparison\")\n",
    "println(\"=\".repeat(50))\n",
    "println(\"Input\\t\\tNetwork Output\\tMath.sin()\\tDifference\")\n",
    "println(\"-\".repeat(50))\n",
    "\n",
    "var totalError = 0.0\n",
    "\n",
    "for (i in 0 until numSamples) {\n",
    "    // Generate input value from 0 to π/2\n",
    "    val x = (i.toFloat() / (numSamples - 1)) * maxInput\n",
    "\n",
    "    //val predicted = //with(backend)  {\n",
    "    // Create input tensor\n",
    "    val inputTensor = CpuTensorFP32.fromArray(\n",
    "        Shape(1, 1),\n",
    "        floatArrayOf(x)\n",
    "    )\n",
    "\n",
    "    // Get network prediction\n",
    "    val output = with(sinNetwork) { forward(inputTensor) }\n",
    "    val predicted = output[0,0]\n",
    "    //}\n",
    "    // Calculate true sin value\n",
    "    val actual = sin(x.toDouble()).toFloat()\n",
    "\n",
    "    // Calculate difference\n",
    "    val difference = abs(predicted - actual)\n",
    "    totalError += difference.toDouble()\n",
    "\n",
    "    // Print comparison (every 10th sample for readability)\n",
    "    if (i % 10 == 0) {\n",
    "        println(\"%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\".format(x, predicted, actual, difference))\n",
    "    }\n",
    "}\n",
    "\n",
    "val meanAbsoluteError = totalError / numSamples\n",
    "println(\"-\".repeat(50))\n",
    "println(\"Mean Absolute Error: %.6f\".format(meanAbsoluteError))\n",
    "println(\"Network approximation quality: ${if (meanAbsoluteError < 0.1) \"Good\" else \"Needs improvement\"}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network vs Math.sin() Comparison\n",
      "==================================================\n",
      "Input\t\tNetwork Output\tMath.sin()\tDifference\n",
      "--------------------------------------------------\n",
      "0,0000\t\t0,1410\t\t0,0000\t\t0,1410\n",
      "0,1587\t\t0,5718\t\t0,1580\t\t0,4138\n",
      "0,3173\t\t1,0652\t\t0,3120\t\t0,7532\n",
      "0,4760\t\t1,4900\t\t0,4582\t\t1,0318\n",
      "0,6347\t\t1,9227\t\t0,5929\t\t1,3298\n",
      "0,7933\t\t2,3747\t\t0,7127\t\t1,6620\n",
      "0,9520\t\t2,8202\t\t0,8146\t\t2,0056\n",
      "1,1107\t\t3,2628\t\t0,8960\t\t2,3668\n",
      "1,2693\t\t3,7040\t\t0,9549\t\t2,7491\n",
      "1,4280\t\t4,1453\t\t0,9898\t\t3,1554\n",
      "--------------------------------------------------\n",
      "Mean Absolute Error: 1,713441\n",
      "Network approximation quality: Needs improvement\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "2.2.20-Beta2",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
